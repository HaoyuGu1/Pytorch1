{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed4a4d5",
   "metadata": {},
   "source": [
    "# MNIST Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93828254",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "046e50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = {'batch_size': 64, 'num_workers': 1, 'pin_memory': True, 'shuffle': True}\n",
    "test_kwargs = {'batch_size': 1000, 'num_workers': 1, 'pin_memory': True, 'shuffle': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2522ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transform)\n",
    "dataset2 = datasets.MNIST('../data', train=False,\n",
    "                       transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "872a09a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f249e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5656c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efe1297a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3860, -0.1951,\n",
       "           -0.1951, -0.1951,  1.1795,  1.3068,  1.8032, -0.0933,  1.6887,\n",
       "            2.8215,  2.7197,  1.1923, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.0424,  0.0340,  0.7722,  1.5359,  1.7396,  2.7960,\n",
       "            2.7960,  2.7960,  2.7960,  2.7960,  2.4396,  1.7650,  2.7960,\n",
       "            2.6560,  2.0578,  0.3904, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "            0.1995,  2.6051,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
       "            2.7960,  2.7960,  2.7960,  2.7706,  0.7595,  0.6195,  0.6195,\n",
       "            0.2886,  0.0722, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.1951,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
       "            2.0960,  1.8923,  2.7197,  2.6433, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242,  0.5940,  1.5614,  0.9377,  2.7960,  2.7960,  2.1851,\n",
       "           -0.2842, -0.4242,  0.1231,  1.5359, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.2460, -0.4115,  1.5359,  2.7960,  0.7213,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242,  1.3450,  2.7960,  1.9942,\n",
       "           -0.3988, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.2842,  1.9942,  2.7960,\n",
       "            0.4668, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0213,  2.6433,\n",
       "            2.4396,  1.6123,  0.9504, -0.4115, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6068,\n",
       "            2.6306,  2.7960,  2.7960,  1.0904, -0.1060, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "            0.1486,  1.9432,  2.7960,  2.7960,  1.4850, -0.0806, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.2206,  0.7595,  2.7833,  2.7960,  1.9560, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242,  2.7451,  2.7960,  2.7451,  0.3904,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "            0.1613,  1.2305,  1.9051,  2.7960,  2.7960,  2.2105, -0.3988,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0722,  1.4596,\n",
       "            2.4906,  2.7960,  2.7960,  2.7960,  2.7578,  1.8923, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.1187,  1.0268,  2.3887,  2.7960,\n",
       "            2.7960,  2.7960,  2.7960,  2.1342,  0.5686, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.1315,  0.4159,  2.2869,  2.7960,  2.7960,  2.7960,\n",
       "            2.7960,  2.0960,  0.6068, -0.3988, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.1951,\n",
       "            1.7523,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.0578,\n",
       "            0.5940, -0.3097, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242,  0.2758,  1.7650,  2.4524,\n",
       "            2.7960,  2.7960,  2.7960,  2.7960,  2.6815,  1.2686, -0.2842,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242,  1.3068,  2.7960,  2.7960,\n",
       "            2.7960,  2.2742,  1.2941,  1.2559, -0.2206, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]]),\n",
       " 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "079d3795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e312249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9522f61900>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOX0lEQVR4nO3dbYxc5XnG8euKbUwxJvHGseMQFxzjFAg0Jl0ZkBFQoVCCIgGKCLGiiFBapwlOQutKUFoVWtHKrRIiSimSKS6m4iWQgPAHmsSyECRqcFmoAROHN+MS4+0aswIDIfZ6fffDjqsFdp5dZs68eO//T1rNzLnnzLk1cPmcmeeceRwRAjD5faDTDQBoD8IOJEHYgSQIO5AEYQeSmNrOjR3i6XGoZrRzk0Aqv9Fb2ht7PFatqbDbPkfS9ZKmSPrXiFhVev6hmqGTfVYzmwRQsDE21K01fBhve4qkGyV9TtLxkpbZPr7R1wPQWs18Zl8i6fmI2BoReyXdJem8atoCULVmwn6kpF+Nery9tuwdbC+33We7b0h7mtgcgGY0E/axvgR4z7m3EbE6InojoneapjexOQDNaCbs2yXNH/X445J2NNcOgFZpJuyPSlpke4HtQyR9SdK6atoCULWGh94iYp/tFZJ+rJGhtzUR8XRlnQGoVFPj7BHxgKQHKuoFQAtxuiyQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJNDWLK7qfp5b/E0/5yOyWbv+ZPz+6bm34sP3FdY9auLNYP+wbLtb/97pD6tYe7/1+cd1dw28V6yffs7JYP+bPHinWO6GpsNveJukNScOS9kVEbxVNAaheFXv234+IXRW8DoAW4jM7kESzYQ9JP7H9mO3lYz3B9nLbfbb7hrSnyc0BaFSzh/FLI2KH7TmS1tv+ZUQ8PPoJEbFa0mpJOsI90eT2ADSoqT17ROyo3e6UdJ+kJVU0BaB6DYfd9gzbMw/cl3S2pM1VNQagWs0cxs+VdJ/tA69zR0T8qJKuJpkpxy0q1mP6tGJ9xxkfKtbfPqX+mHDPB8vjxT/9dHm8uZP+49czi/V/+OdzivWNJ95Rt/bi0NvFdVcNfLZY/9hPD75PpA2HPSK2Svp0hb0AaCGG3oAkCDuQBGEHkiDsQBKEHUiCS1wrMHzmZ4r16269sVj/5LT6l2JOZkMxXKz/9Q1fLdanvlUe/jr1nhV1azNf3ldcd/qu8tDcYX0bi/VuxJ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnL0C05/ZUaw/9pv5xfonpw1U2U6lVvafUqxvfbP8U9S3LvxB3drr+8vj5HP/6T+L9VY6+C5gHR97diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwhHtG1E8wj1xss9q2/a6xeAlpxbru88p/9zzlCcPL9af+MYN77unA67d9bvF+qNnlMfRh197vViPU+v/APG2bxVX1YJlT5SfgPfYGBu0OwbHnMuaPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4exeYMvvDxfrwq4PF+ot31B8rf/r0NcV1l/z9N4v1OTd27ppyvH9NjbPbXmN7p+3No5b12F5v+7na7awqGwZQvYkcxt8q6d2z3l8paUNELJK0ofYYQBcbN+wR8bCkdx9Hnidpbe3+WknnV9sWgKo1+gXd3Ijol6Ta7Zx6T7S93Haf7b4h7WlwcwCa1fJv4yNidUT0RkTvNE1v9eYA1NFo2Adsz5Ok2u3O6loC0AqNhn2dpItr9y+WdH817QBolXF/N972nZLOlDTb9nZJV0taJelu25dKeknSha1scrIb3vVqU+sP7W58fvdPffkXxforN00pv8D+8hzr6B7jhj0iltUpcXYMcBDhdFkgCcIOJEHYgSQIO5AEYQeSYMrmSeC4K56tW7vkxPKgyb8dtaFYP+PCy4r1md9/pFhH92DPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+CZSmTX7168cV131p3dvF+pXX3las/8UXLyjW478/WLc2/+9+XlxXbfyZ8wzYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEkzZnNzgH55arN9+9XeK9QVTD21425+6bUWxvujm/mJ939ZtDW97smpqymYAkwNhB5Ig7EAShB1IgrADSRB2IAnCDiTBODuKYuniYv2IVduL9Ts/8eOGt33sg39UrP/O39S/jl+Shp/b2vC2D1ZNjbPbXmN7p+3No5ZdY/tl25tqf+dW2TCA6k3kMP5WSeeMsfx7EbG49vdAtW0BqNq4YY+IhyUNtqEXAC3UzBd0K2w/WTvMn1XvSbaX2+6z3TekPU1sDkAzGg37TZIWSlosqV/Sd+s9MSJWR0RvRPRO0/QGNwegWQ2FPSIGImI4IvZLulnSkmrbAlC1hsJue96ohxdI2lzvuQC6w7jj7LbvlHSmpNmSBiRdXXu8WFJI2ibpaxFRvvhYjLNPRlPmzinWd1x0TN3axiuuL677gXH2RV9+8exi/fXTXi3WJ6PSOPu4k0RExLIxFt/SdFcA2orTZYEkCDuQBGEHkiDsQBKEHUiCS1zRMXdvL0/ZfJgPKdZ/HXuL9c9/8/L6r33fxuK6Byt+ShoAYQeyIOxAEoQdSIKwA0kQdiAJwg4kMe5Vb8ht/2mLi/UXLixP2XzC4m11a+ONo4/nhsGTivXD7u9r6vUnG/bsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+yTnHtPKNaf/VZ5rPvmpWuL9dMPLV9T3ow9MVSsPzK4oPwC+8f9dfNU2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMsx8Epi44qlh/4ZKP1a1dc9FdxXW/cPiuhnqqwlUDvcX6Q9efUqzPWlv+3Xm807h7dtvzbT9oe4vtp21/u7a8x/Z628/Vbme1vl0AjZrIYfw+SSsj4jhJp0i6zPbxkq6UtCEiFknaUHsMoEuNG/aI6I+Ix2v335C0RdKRks6TdOBcyrWSzm9RjwAq8L6+oLN9tKSTJG2UNDci+qWRfxAkzamzznLbfbb7hrSnyXYBNGrCYbd9uKQfSro8InZPdL2IWB0RvRHRO03TG+kRQAUmFHbb0zQS9Nsj4t7a4gHb82r1eZJ2tqZFAFUYd+jNtiXdImlLRFw3qrRO0sWSVtVu729Jh5PA1KN/u1h//ffmFesX/e2PivU/+dC9xXorrewvD4/9/F/qD6/13PpfxXVn7WdorUoTGWdfKukrkp6yvam27CqNhPxu25dKeknShS3pEEAlxg17RPxM0piTu0s6q9p2ALQKp8sCSRB2IAnCDiRB2IEkCDuQBJe4TtDUeR+tWxtcM6O47tcXPFSsL5s50FBPVVjx8mnF+uM3LS7WZ/9gc7He8wZj5d2CPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJJFmnH3vH5R/tnjvnw4W61cd80Dd2tm/9VZDPVVlYPjturXT160srnvsX/2yWO95rTxOvr9YRTdhzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSaQZZ992fvnftWdPvKdl277xtYXF+vUPnV2se7jej/uOOPbaF+vWFg1sLK47XKxiMmHPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJOCLKT7DnS7pN0kc1cvny6oi43vY1kv5Y0iu1p14VEfUv+pZ0hHviZDPxK9AqG2ODdsfgmCdmTOSkmn2SVkbE47ZnSnrM9vpa7XsR8Z2qGgXQOhOZn71fUn/t/hu2t0g6stWNAajW+/rMbvtoSSdJOnAO5grbT9peY3tWnXWW2+6z3TekPc11C6BhEw677cMl/VDS5RGxW9JNkhZKWqyRPf93x1ovIlZHRG9E9E7T9OY7BtCQCYXd9jSNBP32iLhXkiJiICKGI2K/pJslLWldmwCaNW7YbVvSLZK2RMR1o5bPG/W0CySVp/ME0FET+TZ+qaSvSHrK9qbasqskLbO9WFJI2ibpay3oD0BFJvJt/M8kjTVuVxxTB9BdOIMOSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQxLg/JV3pxuxXJP3PqEWzJe1qWwPvT7f21q19SfTWqCp7OyoiPjJWoa1hf8/G7b6I6O1YAwXd2lu39iXRW6Pa1RuH8UAShB1IotNhX93h7Zd0a2/d2pdEb41qS28d/cwOoH06vWcH0CaEHUiiI2G3fY7tZ2w/b/vKTvRQj+1ttp+yvcl2X4d7WWN7p+3No5b12F5v+7na7Zhz7HWot2tsv1x77zbZPrdDvc23/aDtLbaftv3t2vKOvneFvtryvrX9M7vtKZKelfRZSdslPSppWUT8oq2N1GF7m6TeiOj4CRi2T5f0pqTbIuKE2rJ/lDQYEatq/1DOiogruqS3ayS92elpvGuzFc0bPc24pPMlfVUdfO8KfX1RbXjfOrFnXyLp+YjYGhF7Jd0l6bwO9NH1IuJhSYPvWnyepLW1+2s18j9L29XprStERH9EPF67/4akA9OMd/S9K/TVFp0I+5GSfjXq8XZ113zvIeknth+zvbzTzYxhbkT0SyP/80ia0+F+3m3cabzb6V3TjHfNe9fI9OfN6kTYx5pKqpvG/5ZGxGckfU7SZbXDVUzMhKbxbpcxphnvCo1Of96sToR9u6T5ox5/XNKODvQxpojYUbvdKek+dd9U1AMHZtCt3e7scD//r5um8R5rmnF1wXvXyenPOxH2RyUtsr3A9iGSviRpXQf6eA/bM2pfnMj2DElnq/umol4n6eLa/Ysl3d/BXt6hW6bxrjfNuDr83nV8+vOIaPufpHM18o38C5L+shM91OnrE5KeqP093eneJN2pkcO6IY0cEV0q6cOSNkh6rnbb00W9/bukpyQ9qZFgzetQb6dp5KPhk5I21f7O7fR7V+irLe8bp8sCSXAGHZAEYQeSIOxAEoQdSIKwA0kQdiAJwg4k8X+zhHFo7nUhhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(dataset1[0][0].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9e115c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(dataset1[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b762f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d0debe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06df6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ac519fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=1.0)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3d4bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dry_run, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            if dry_run:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a4f8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f25600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304086\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.483454\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.553788\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.329113\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.429457\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.138165\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.138324\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.106210\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.077803\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.131333\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.026926\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.044464\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.055920\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.134737\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.083895\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.211297\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.044227\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.038829\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.133101\n",
      "\n",
      "Test set: Average loss: 0.0453, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.068935\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.025827\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.036748\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.009165\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.034569\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.041076\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.067809\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.006986\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.176369\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.015830\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.024627\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.120578\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.004441\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.068772\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.041876\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.036133\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.180075\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.023938\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.009721\n",
      "\n",
      "Test set: Average loss: 0.0363, Accuracy: 9879/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.151827\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.022769\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.009587\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.148401\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.046925\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.204460\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.026152\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.034202\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.006462\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.035811\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.091731\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.065846\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.044159\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.007944\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.031157\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.004689\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.006645\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.012520\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.021701\n",
      "\n",
      "Test set: Average loss: 0.0358, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.017820\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.005245\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.011117\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.012314\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.053708\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.019360\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.037697\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.008664\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.028219\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.047608\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.011517\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.163093\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.092249\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.006683\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.005895\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.003299\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.028930\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.005765\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.057321\n",
      "\n",
      "Test set: Average loss: 0.0291, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.005983\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.027719\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.007718\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.003807\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.062214\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.005368\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.001086\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.040702\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.058768\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.009829\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.035533\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.018205\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.007692\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.018107\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.076740\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.140321\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.016024\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.057671\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.027249\n",
      "\n",
      "Test set: Average loss: 0.0289, Accuracy: 9911/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.031237\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.025852\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.010477\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.026485\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.020630\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.000460\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.084963\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.011054\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.020268\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.012857\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.007072\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.042861\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.002863\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.004465\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.028030\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.008660\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.031442\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.004995\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.001316\n",
      "\n",
      "Test set: Average loss: 0.0287, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.116758\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.044722\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.130645\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.081057\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.043891\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.035503\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.016339\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.008756\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.024321\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.017221\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.019142\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.001405\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.034544\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.042996\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.015506\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.040036\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.039684\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.021614\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.022343\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.047210\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.013396\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.028145\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.064660\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.032066\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.043324\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.002806\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.080810\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.074458\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.049314\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.000767\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.002614\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.006574\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.034785\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.015252\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.060464\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.002489\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.013407\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.018576\n",
      "\n",
      "Test set: Average loss: 0.0277, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.004137\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.219774\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.011975\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.003798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.009582\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.051869\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.149949\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.007237\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.011666\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.003852\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.042090\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.018689\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.002339\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.026952\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.004560\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.110791\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.005805\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.012774\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.019638\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 9914/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.005552\n",
      "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.011325\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.106327\n",
      "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.016725\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.014983\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.008195\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.004805\n",
      "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.007613\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.005262\n",
      "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.015021\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.007859\n",
      "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.006763\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.007447\n",
      "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.006996\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.009767\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.002931\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.006214\n",
      "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.040586\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.010895\n",
      "\n",
      "Test set: Average loss: 0.0272, Accuracy: 9912/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.020540\n",
      "Train Epoch: 11 [3200/60000 (5%)]\tLoss: 0.010748\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.033409\n",
      "Train Epoch: 11 [9600/60000 (16%)]\tLoss: 0.032415\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.024565\n",
      "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.000984\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.004040\n",
      "Train Epoch: 11 [22400/60000 (37%)]\tLoss: 0.061551\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.041262\n",
      "Train Epoch: 11 [28800/60000 (48%)]\tLoss: 0.030136\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.002762\n",
      "Train Epoch: 11 [35200/60000 (59%)]\tLoss: 0.010743\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.005233\n",
      "Train Epoch: 11 [41600/60000 (69%)]\tLoss: 0.117578\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.009364\n",
      "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.014623\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.003061\n",
      "Train Epoch: 11 [54400/60000 (91%)]\tLoss: 0.006869\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.003255\n",
      "\n",
      "Test set: Average loss: 0.0263, Accuracy: 9912/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.030275\n",
      "Train Epoch: 12 [3200/60000 (5%)]\tLoss: 0.004557\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.004224\n",
      "Train Epoch: 12 [9600/60000 (16%)]\tLoss: 0.003952\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.012795\n",
      "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.052782\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.044178\n",
      "Train Epoch: 12 [22400/60000 (37%)]\tLoss: 0.006386\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.005551\n",
      "Train Epoch: 12 [28800/60000 (48%)]\tLoss: 0.000987\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.017901\n",
      "Train Epoch: 12 [35200/60000 (59%)]\tLoss: 0.053025\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.003934\n",
      "Train Epoch: 12 [41600/60000 (69%)]\tLoss: 0.176611\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.006120\n",
      "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.025429\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.000851\n",
      "Train Epoch: 12 [54400/60000 (91%)]\tLoss: 0.009207\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.027490\n",
      "\n",
      "Test set: Average loss: 0.0267, Accuracy: 9913/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.011479\n",
      "Train Epoch: 13 [3200/60000 (5%)]\tLoss: 0.020575\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.003176\n",
      "Train Epoch: 13 [9600/60000 (16%)]\tLoss: 0.013525\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.024242\n",
      "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.002399\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.000668\n",
      "Train Epoch: 13 [22400/60000 (37%)]\tLoss: 0.025648\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.011894\n",
      "Train Epoch: 13 [28800/60000 (48%)]\tLoss: 0.037351\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.000562\n",
      "Train Epoch: 13 [35200/60000 (59%)]\tLoss: 0.012582\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.013998\n",
      "Train Epoch: 13 [41600/60000 (69%)]\tLoss: 0.001727\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.033062\n",
      "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.004695\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.014415\n",
      "Train Epoch: 13 [54400/60000 (91%)]\tLoss: 0.001962\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.004545\n",
      "\n",
      "Test set: Average loss: 0.0266, Accuracy: 9912/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.049028\n",
      "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.022294\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.125557\n",
      "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.001006\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.017536\n",
      "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.008574\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.003895\n",
      "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.008526\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.006649\n",
      "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.054258\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.010476\n",
      "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.000951\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.011821\n",
      "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.002824\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.055428\n",
      "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.062347\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.003034\n",
      "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.002490\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.008748\n",
      "\n",
      "Test set: Average loss: 0.0264, Accuracy: 9917/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dry_run = False\n",
    "n_epochs = 14\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(dry_run, model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb7ed1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = False\n",
    "if save_model:\n",
    "    torch.save(model.state_dict(), \"mnist_cnn.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
